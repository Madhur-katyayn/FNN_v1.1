{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iSrteUNHysvr"
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Converting to fixed point\n",
    "def convert_to_fixed_point_for_weights(arr, size, width, after_decimal, part_number, part_width):\n",
    "  i=0\n",
    "  binary_array=[]\n",
    "  while(i<size):\n",
    "    binary_number=''\n",
    "    number=arr[i]\n",
    "    if(number>=0):\n",
    "      binary_number=binary_number+positive_num_to_fixedpoint(number, width, after_decimal,part_number,part_width)\n",
    "    elif(number<0):\n",
    "      binary_number=binary_number+negative_num_to_fixedpoint(abs(number), width, after_decimal, part_number,part_width)\n",
    "    i=i+1\n",
    "    binary_array.append(binary_number)\n",
    "  return binary_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#Converting to fixed point\n",
    "def convert_to_fixed_point_for_bias(arr, size, width, after_decimal, part_number, part_width):\n",
    "  i=0\n",
    "  binary_array=[]\n",
    "  while(i<size):\n",
    "    binary_number=''\n",
    "    part_number_temp=part_number[i]\n",
    "    number=arr[i]\n",
    "    if(number>=0):\n",
    "      binary_number=binary_number+positive_num_to_fixedpoint(number, width, after_decimal,part_number_temp,part_width)\n",
    "    elif(number<0):\n",
    "      binary_number=binary_number+negative_num_to_fixedpoint(abs(number), width, after_decimal, part_number_temp,part_width)\n",
    "    i=i+1\n",
    "    binary_array.append(binary_number)\n",
    "  return binary_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_num_to_fixedpoint(number, width, after_decimal, part_number,part_width):\n",
    "  new_num=number*(2**after_decimal)\n",
    "  new_num =round(new_num)\n",
    "  # binary_array=[]\n",
    "  # decimal_num=number\n",
    "  s=bin(new_num)\n",
    "  s1 = s[2:]\n",
    "  lenght_binary_string=len(s1)\n",
    "  temp_str='0'\n",
    "  k=0\n",
    "  while(k<(width-lenght_binary_string-1)):\n",
    "    temp_str=temp_str+'0'\n",
    "    k=k+1\n",
    "  k=0\n",
    "  while(k<lenght_binary_string):\n",
    "    temp_str=temp_str+s1[k]\n",
    "    k=k+1\n",
    "  part_number_binary_temp=bin(part_number)\n",
    "  part_number_binary=part_number_binary_temp[2:]\n",
    "  lenght_part_number_binary=len(part_number_binary)\n",
    "  temp_str_1=''\n",
    "  k=0\n",
    "  while(k<(part_width-lenght_part_number_binary)):\n",
    "    temp_str_1=temp_str_1+'0'\n",
    "    k=k+1\n",
    "  k=0\n",
    "  while(k<lenght_part_number_binary):\n",
    "    temp_str_1=temp_str_1+part_number_binary[k]\n",
    "    k=k+1\n",
    "  temp_str=temp_str+temp_str_1\n",
    "  # binary_array.append(temp_str)\n",
    "\n",
    "  return temp_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_num_to_fixedpoint(number, width, after_decimal, part_number, part_width):\n",
    "  new_num=number*(2**after_decimal)\n",
    "  new_num =round(new_num)\n",
    "  if(new_num==0):\n",
    "    temp_str=positive_num_to_fixedpoint(number, width, after_decimal, part_number, part_width)\n",
    "  else:\n",
    "      two_s_complement=2**(width-1)-new_num\n",
    "      # binary_array=[]\n",
    "      # decimal_num=number\n",
    "      s=bin(two_s_complement)\n",
    "      s1 = s[2:]\n",
    "      lenght_binary_string=len(s1)\n",
    "      temp_str='1'\n",
    "      k=0\n",
    "      while(k<(width-lenght_binary_string-1)):\n",
    "        temp_str=temp_str+'1'\n",
    "        k=k+1\n",
    "      k=0\n",
    "      while(k<lenght_binary_string):\n",
    "        temp_str=temp_str+s1[k]\n",
    "        k=k+1\n",
    "\n",
    "      part_number_binary_temp=bin(part_number)\n",
    "      part_number_binary=part_number_binary_temp[2:]\n",
    "      lenght_part_number_binary=len(part_number_binary)\n",
    "      temp_str_1=''\n",
    "      k=0\n",
    "      while(k<(part_width-lenght_part_number_binary)):\n",
    "        temp_str_1=temp_str_1+'0'\n",
    "        k=k+1\n",
    "      k=0\n",
    "      while(k<lenght_part_number_binary):\n",
    "        temp_str_1=temp_str_1+part_number_binary[k]\n",
    "        k=k+1\n",
    "      temp_str=temp_str+temp_str_1\n",
    "  # binary_array.append(temp_str)\n",
    "  return temp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XY3qKmEMyvzS",
    "outputId": "1b21ccaa-4285-4675-da2d-8a5e3f2c0fa2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 1.7103 - accuracy: 0.7580 - val_loss: 1.6060 - val_accuracy: 0.8590\n",
      "Epoch 2/25\n",
      "1688/1688 [==============================] - 2s 935us/step - loss: 1.6090 - accuracy: 0.8545 - val_loss: 1.5997 - val_accuracy: 0.8623\n",
      "Epoch 3/25\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 1.5986 - accuracy: 0.8636 - val_loss: 1.5859 - val_accuracy: 0.8760\n",
      "Epoch 4/25\n",
      "1688/1688 [==============================] - 1s 883us/step - loss: 1.5926 - accuracy: 0.8692 - val_loss: 1.5882 - val_accuracy: 0.8730\n",
      "Epoch 5/25\n",
      "1688/1688 [==============================] - 2s 969us/step - loss: 1.5888 - accuracy: 0.8726 - val_loss: 1.5832 - val_accuracy: 0.8780\n",
      "Epoch 6/25\n",
      "1688/1688 [==============================] - 2s 927us/step - loss: 1.5603 - accuracy: 0.9027 - val_loss: 1.5178 - val_accuracy: 0.9448\n",
      "Epoch 7/25\n",
      "1688/1688 [==============================] - 2s 942us/step - loss: 1.5139 - accuracy: 0.9493 - val_loss: 1.5045 - val_accuracy: 0.9580\n",
      "Epoch 8/25\n",
      "1688/1688 [==============================] - 2s 896us/step - loss: 1.5055 - accuracy: 0.9574 - val_loss: 1.5012 - val_accuracy: 0.9622\n",
      "Epoch 9/25\n",
      "1688/1688 [==============================] - 2s 922us/step - loss: 1.5010 - accuracy: 0.9617 - val_loss: 1.4992 - val_accuracy: 0.9625\n",
      "Epoch 10/25\n",
      "1688/1688 [==============================] - 2s 896us/step - loss: 1.4979 - accuracy: 0.9645 - val_loss: 1.5001 - val_accuracy: 0.9620\n",
      "Epoch 11/25\n",
      "1688/1688 [==============================] - 2s 943us/step - loss: 1.4951 - accuracy: 0.9674 - val_loss: 1.4958 - val_accuracy: 0.9658\n",
      "Epoch 12/25\n",
      "1688/1688 [==============================] - 2s 926us/step - loss: 1.4938 - accuracy: 0.9683 - val_loss: 1.4959 - val_accuracy: 0.9663\n",
      "Epoch 13/25\n",
      "1688/1688 [==============================] - 1s 869us/step - loss: 1.4925 - accuracy: 0.9693 - val_loss: 1.4953 - val_accuracy: 0.9667\n",
      "Epoch 14/25\n",
      "1688/1688 [==============================] - 2s 927us/step - loss: 1.4912 - accuracy: 0.9708 - val_loss: 1.4942 - val_accuracy: 0.9667\n",
      "Epoch 15/25\n",
      "1688/1688 [==============================] - 1s 880us/step - loss: 1.4900 - accuracy: 0.9719 - val_loss: 1.4937 - val_accuracy: 0.9673\n",
      "Epoch 16/25\n",
      "1688/1688 [==============================] - 2s 898us/step - loss: 1.4892 - accuracy: 0.9725 - val_loss: 1.4944 - val_accuracy: 0.9670\n",
      "Epoch 17/25\n",
      "1688/1688 [==============================] - 2s 938us/step - loss: 1.4884 - accuracy: 0.9733 - val_loss: 1.4955 - val_accuracy: 0.9655\n",
      "Epoch 18/25\n",
      "1688/1688 [==============================] - 2s 936us/step - loss: 1.4868 - accuracy: 0.9750 - val_loss: 1.4966 - val_accuracy: 0.9647\n",
      "Epoch 19/25\n",
      "1688/1688 [==============================] - 2s 968us/step - loss: 1.4870 - accuracy: 0.9744 - val_loss: 1.4962 - val_accuracy: 0.9652\n",
      "Epoch 20/25\n",
      "1688/1688 [==============================] - 1s 887us/step - loss: 1.4861 - accuracy: 0.9754 - val_loss: 1.4944 - val_accuracy: 0.9683\n",
      "Epoch 21/25\n",
      "1688/1688 [==============================] - 2s 938us/step - loss: 1.4855 - accuracy: 0.9760 - val_loss: 1.4942 - val_accuracy: 0.9670\n",
      "Epoch 22/25\n",
      "1688/1688 [==============================] - 2s 956us/step - loss: 1.4845 - accuracy: 0.9769 - val_loss: 1.4944 - val_accuracy: 0.9665\n",
      "Epoch 23/25\n",
      "1688/1688 [==============================] - 2s 958us/step - loss: 1.4839 - accuracy: 0.9778 - val_loss: 1.4940 - val_accuracy: 0.9667\n",
      "Epoch 24/25\n",
      "1688/1688 [==============================] - 2s 997us/step - loss: 1.4842 - accuracy: 0.9773 - val_loss: 1.4935 - val_accuracy: 0.9673\n",
      "Epoch 25/25\n",
      "1688/1688 [==============================] - 2s 957us/step - loss: 1.4838 - accuracy: 0.9775 - val_loss: 1.4925 - val_accuracy: 0.9683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16b77d32e80>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load MNIST dataset\n",
    "mnist = keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the input image so that each pixel value is between 0 to 1.\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Define the model architecture.\n",
    "model = keras.Sequential([\n",
    "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "  # keras.layers.Conv2D(filters=1, kernel_size=(3, 3), activation='relu'),\n",
    "  # keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "  keras.layers.Flatten(),\n",
    "  keras.layers.Dense(40,activation='relu'),\n",
    "  keras.layers.Dense(10,activation='relu'),\n",
    "  keras.layers.Dense(10,activation='relu'),\n",
    "  keras.layers.Dense(10,activation='softmax')\n",
    "])\n",
    "\n",
    "# Train the digit classification model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(\n",
    "  train_images,\n",
    "  train_labels,\n",
    "  epochs=25,\n",
    "  validation_split=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hfA_3scon3Nq",
    "outputId": "9ee21b05-23c9-49fa-88ad-73ca206941d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.layers.core.Reshape object at 0x0000016B77B892B0>\n",
      "<tensorflow.python.keras.layers.core.Flatten object at 0x0000016B77B89A60>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x0000016B77B89970>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x0000016B77B89B50>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x0000016B77BA6460>\n",
      "<tensorflow.python.keras.layers.core.Dense object at 0x0000016B77BA6790>\n"
     ]
    }
   ],
   "source": [
    "for item in model.layers:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00708336,  0.07424793, -0.02322672, ..., -0.06675178,\n",
       "        -0.0438978 ,  0.02643612],\n",
       "       [-0.04047094,  0.00287376,  0.0161667 , ...,  0.05150773,\n",
       "         0.03856693,  0.03647736],\n",
       "       [ 0.01651584,  0.03965481,  0.0374746 , ...,  0.0628909 ,\n",
       "         0.04701933, -0.02886365],\n",
       "       ...,\n",
       "       [ 0.05099992, -0.01902571, -0.054472  , ..., -0.07160176,\n",
       "        -0.02318082, -0.00183503],\n",
       "       [ 0.01795533,  0.05255714,  0.02247441, ..., -0.0079519 ,\n",
       "        -0.00067309, -0.07913768],\n",
       "       [ 0.04158127, -0.04773584,  0.06603992, ..., -0.08096097,\n",
       "         0.05192146, -0.01693273]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_weights = model.layers[2].get_weights()[0]\n",
    "layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 40)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "textfile = open(\"weights_and_biases.mif\", \"w\")\n",
    "layers = [784, 40, 10, 10,10]\n",
    "for_bias= [0, 40, 50, 60,70]\n",
    "data_width=16\n",
    "after_decimal=14\n",
    "k = 0\n",
    "part_width=7\n",
    "while(k<4):\n",
    "    layer_weights = []\n",
    "    layer_weights = model.layers[2+k].get_weights()[0]\n",
    "    j=0\n",
    "    layer_1_bias = model.layers[2+k].get_weights()[1] \n",
    "    part_number_bias=np.arange(for_bias[k],for_bias[k+1],1)\n",
    "    layer_1_bias_binary = convert_to_fixed_point_for_bias(layer_1_bias, layers[k+1], data_width, after_decimal, part_number_bias, part_width)\n",
    "    while(j<layers[k+1]):\n",
    "        l1_n1_w=[]\n",
    "        i=0\n",
    "        while(i<layers[k]):\n",
    "            l1_n1_w.append(layer_weights[i][j])\n",
    "            i=i+1\n",
    "        l1_n1_w_binary = convert_to_fixed_point_for_weights(l1_n1_w, layers[k], data_width, after_decimal,part_number_bias[j],part_width)\n",
    "\n",
    "        textfile = open(\"weights_and_biases.mif\", \"a\")\n",
    "        for element in l1_n1_w_binary:\n",
    "            textfile.write(element + \"\\n\")\n",
    "        textfile.close()\n",
    "        layer_1_bias_binary_n = layer_1_bias_binary[j]\n",
    "        textfile = open(\"weights_and_biases.mif\", \"a\")\n",
    "        textfile.write(layer_1_bias_binary_n + \"\\n\")\n",
    "        textfile.close()\n",
    "        j=j+1\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pWaTuuKyvGqK",
    "outputId": "bbcf1e57-3eef-45a8-f400-79b0ec49e6f5",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000000000000000001000', '0000000000000000000101']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr=np.array([-0.000007939605,0])\n",
    "size=2\n",
    "width=16\n",
    "after_decimal=14\n",
    "k=np.array([8,5])\n",
    "convert_to_fixed_point_for_bias(arr,size,width,after_decimal,k,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_num_to_fixedpoint_for_image(number, width, after_decimal):\n",
    "  new_num=number*(2**after_decimal)\n",
    "  new_num =round(new_num)\n",
    "  # binary_array=[]\n",
    "  # decimal_num=number\n",
    "  s=bin(new_num)\n",
    "  s1 = s[2:]\n",
    "  lenght_binary_string=len(s1)\n",
    "  temp_str='0'\n",
    "  k=0\n",
    "  while(k<(width-lenght_binary_string-1)):\n",
    "    temp_str=temp_str+'0'\n",
    "    k=k+1\n",
    "  k=0\n",
    "  while(k<lenght_binary_string):\n",
    "    temp_str=temp_str+s1[k]\n",
    "    k=k+1\n",
    "  # binary_array.append(temp_str)\n",
    "\n",
    "  return temp_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_fixed_point_for_image(arr, size, width, after_decimal):\n",
    "  i=0\n",
    "  binary_array=[]\n",
    "  while(i<size):\n",
    "    binary_number=''\n",
    "    number=arr[i]\n",
    "    if(number>=0):\n",
    "      binary_number=binary_number+positive_num_to_fixedpoint_for_image(number, width, after_decimal)\n",
    "    i=i+1\n",
    "    binary_array.append(binary_number)\n",
    "  return binary_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_and_convert_to_fixed_point(image, no_of_inputs, word_width, after_decimal):\n",
    "    i=0\n",
    "    j=0\n",
    "    k=0\n",
    "    flatten_image=np.zeros(784)\n",
    "    while(i<28):\n",
    "        j=0\n",
    "        while(j<28):\n",
    "            flatten_image[k]=image[i][j]\n",
    "            j=j+1\n",
    "            k=k+1\n",
    "        i=i+1\n",
    "    image_in_fixed_point=convert_to_fixed_point_for_image(flatten_image,no_of_inputs,word_width,after_decimal)\n",
    "    return image_in_fixed_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import image\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "# load image as pixel array\n",
    "i=0\n",
    "while(i<10):\n",
    "    image_array = image.imread(\"I_\"+str(i)+\".png\")\n",
    "    image_in_fixed_point=flatten_and_convert_to_fixed_point(image_array,784,16,14)\n",
    "    textfile = open(\"input_data_\"+str(i)+\".mif\", \"w\")\n",
    "    for element in image_in_fixed_point:\n",
    "        textfile.write(element + \"\\n\")\n",
    "    textfile.close()\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_array = image.imread(\"I_2.png\")\n",
    "i=0\n",
    "j=0\n",
    "k=0\n",
    "flatten_image=np.zeros(784)\n",
    "while(i<28):\n",
    "    j=0\n",
    "    while(j<28):\n",
    "        flatten_image[k]=image_array[i][j]\n",
    "        j=j+1\n",
    "        k=k+1\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_weights = model.layers[2].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight = image.imread(\"I_2.png\")\n",
    "# i=0\n",
    "j=0\n",
    "k=0\n",
    "weight_array=np.zeros(784)\n",
    "# j=0\n",
    "while(j<784):\n",
    "    weight_array[k]=layer_weights[j][1]\n",
    "    j=j+1\n",
    "    k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "N2_out=sum(weight_array* flatten_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.021040450246518"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N2_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_weights = model.layers[2].get_weights()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.1472045 ,  0.01214375, -0.11490054, -0.23939754,  0.29701558,\n",
       "       -0.12859206,  0.06464671,  0.02230126, -0.03157416,  0.15093336,\n",
       "       -0.24429096, -0.13417256,  0.09303962,  0.22166802, -0.21281384,\n",
       "        0.02424962,  0.2493815 ,  0.16623214, -0.3416569 ,  0.23574005,\n",
       "        0.53174025,  0.3103636 ,  0.2753994 , -0.2858834 , -0.01301405,\n",
       "        0.4003294 ,  0.2536963 ,  0.13762337, -0.08238528, -0.07184153,\n",
       "       -0.01507899,  0.22619247, -0.09429479, -0.07597318,  0.09411906,\n",
       "        0.13093597, -0.29711333, -0.03494006,  0.08807864,  0.28221452],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "name": "Tensorflowmodel.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
